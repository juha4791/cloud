import xarray as xr
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
import os, pickle, hashlib, json
from datetime import datetime, timedelta

class GK2ACloudProcessor:
    """GK2A êµ¬ë¦„ ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self, data_folder="./gk2a_data"):
        self.data_folder = data_folder

    def _md5(self, a: np.ndarray) -> str:
        return hashlib.md5(a.tobytes()).hexdigest()

    def load_cloud_data(self, filepath):
        """NetCDF íŒŒì¼ ë¡œë“œ ë° êµ¬ë¦„ ë°ì´í„° ì¶”ì¶œ"""
        try:
            ds = xr.open_dataset(filepath)

            # GK2A CLD: 0=ë§‘ìŒ, 1=êµ¬ë¦„ê°€ëŠ¥ì„±, 2=êµ¬ë¦„, 3=í™•ì‹¤í•œ êµ¬ë¦„
            if 'CLD' not in ds.variables:
                raise RuntimeError("CLD ë³€ìˆ˜ ì—†ìŒ")

            cld = ds['CLD'].values  # (H,W)
            # ê²°ì¸¡(NaN) -> -1 ì¹˜í™˜
            cld = np.where(np.isfinite(cld), cld, -1).astype(np.int16)

            # ë©”íƒ€ë°ì´í„°
            metadata = {
                'observation_start_time': ds.attrs.get('observation_start_time', ''),
                'projection': ds.attrs.get('projection', ''),
                'resolution': ds.attrs.get('resolution', ''),
                'lat_range': [ds.attrs.get('geospatial_lat_min', 0), ds.attrs.get('geospatial_lat_max', 0)],
                'lon_range': [ds.attrs.get('geospatial_lon_min', 0), ds.attrs.get('geospatial_lon_max', 0)]
            }
            ds.close()
            return cld, metadata

        except Exception as e:
            print(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None, None

    def build_prob_and_binary(self, cld: np.ndarray):
        """
        - í™•ë¥ ì±„ë„(ì—°ì†): CLDë¥¼ 0~1ë¡œ ì„ í˜• ìŠ¤ì¼€ì¼ (ì„ì‹œ ê¸°ì¤€)
          * -1(ê²°ì¸¡)ì€ 0ìœ¼ë¡œ ì²˜ë¦¬
        - ì´ì§„í™”: CLD >= 2 -> 1, ê·¸ ì™¸ 0; ê²°ì¸¡ì€ 0 ì²˜ë¦¬
        """
        cld_clean = cld.copy()
        cld_clean = np.where(cld_clean == -1, 0, cld_clean)
        # 0..3 ë²”ìœ„ë¥¼ 0..1ë¡œ ìŠ¤ì¼€ì¼ (ê°„ë‹¨íˆ /3)
        prob = np.clip(cld_clean.astype(np.float32) / 3.0, 0.0, 1.0)

        binary = (cld_clean >= 2).astype(np.float32)  # 0/1
        return prob, binary

    def create_image_patches(self, arr, patch_size=(256, 256), overlap=0.5):
        """ì´ë¯¸ì§€ë¥¼ íŒ¨ì¹˜ë¡œ ë¶„í• """
        h, w = arr.shape
        step = int(patch_size[0] * (1 - overlap))
        patches, positions = [], []
        for i in range(0, h - patch_size[0] + 1, step):
            for j in range(0, w - patch_size[1] + 1, step):
                patch = arr[i:i+patch_size[0], j:j+patch_size[1]]
                patches.append(patch)
                positions.append((i, j))
        return np.array(patches), positions

    def visualize_cloud_data(self, cloud_mask, title="GK2A Cloud Mask", save_path=None):
        """êµ¬ë¦„ ë°ì´í„° ì‹œê°í™”(ì´ì§„/ì •ìˆ˜ CLD)"""
        plt.figure(figsize=(10, 8))
        vmax = max(3, int(np.nanmax(cloud_mask)))
        colors = ['white', 'lightblue', 'blue', 'darkblue', 'gray']
        cmap = ListedColormap(colors[:vmax+2])
        plt.imshow(cloud_mask, cmap=cmap, vmin=-1, vmax=vmax)
        plt.colorbar(label='CLD (-1,0..3)')
        plt.title(title)
        plt.xlabel('X'); plt.ylabel('Y')
        if save_path:
            plt.savefig(save_path, dpi=200, bbox_inches='tight')
            print(f"âœ… ì´ë¯¸ì§€ ì €ì¥: {save_path}")
        plt.close()

    def collect_time_series(self, start_date, end_date, interval_minutes=10):
        file_list = []
        cur = datetime.strptime(start_date, '%Y%m%d%H%M')
        end = datetime.strptime(end_date, '%Y%m%d%H%M')
        while cur <= end:
            date_str = cur.strftime('%Y%m%d%H%M')
            filename = f"gk2a_ami_le2_cld_ko020lc_{date_str}.nc"
            fp = os.path.join(self.data_folder, filename)
            if os.path.exists(fp):
                file_list.append(fp)
            cur += timedelta(minutes=interval_minutes)
        return file_list


if __name__ == "__main__":
    import glob
    data_folder = r"C:\Users\hwhhs\Desktop\cloud\gk2a_data"
    output_folder = r"C:\Users\hwhhs\Desktop\cloud\processed_cloud_data"
    os.makedirs(output_folder, exist_ok=True)

    all_files = sorted(glob.glob(os.path.join(data_folder, "*.nc")))
    print(f"ğŸ“ ì´ {len(all_files)}ê°œ íŒŒì¼ ë°œê²¬")
    print(f"ğŸ’¾ ì „ì²˜ë¦¬ ê²°ê³¼ ì €ì¥ í´ë”: {output_folder}")

    if not all_files:
        print("âŒ .nc íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        raise SystemExit

    processed_count = failed_count = 0
    dup_guard = {}

    for i, filepath in enumerate(all_files):
        try:
            filename = os.path.basename(filepath).replace(".nc", "")
            print(f"\nğŸ”„ ì²˜ë¦¬ ì¤‘ ({i+1}/{len(all_files)}): {filename}")

            proc = GK2ACloudProcessor(data_folder)
            cld, metadata = proc.load_cloud_data(filepath)
            if cld is None:
                failed_count += 1
                continue

            print(f"âœ… ë°ì´í„° ë¡œë“œ: shape={cld.shape}, unique={np.unique(cld).tolist()[:10]} ...")
            prob, binary = proc.build_prob_and_binary(cld)

            # íŒ¨ì¹˜(í•„ìš” ì‹œ)
            patches, positions = proc.create_image_patches(binary)

            # ë©”íƒ€/í•´ì‹œ/ì»¤ë²„ìœ¨
            prob_md5 = proc._md5(prob)
            bin_md5 = proc._md5(binary)
            coverage = float(binary.mean() * 100.0)

            meta = {
                "original_filepath": filepath,
                "filename": filename,
                "created_at": datetime.now().isoformat(),
                "shape": list(cld.shape),
                "coverage%": coverage,
                "prob_md5": prob_md5,
                "bin_md5": bin_md5,
                "metadata": metadata,
            }

            # ì €ì¥(.pkl)
            save_path = os.path.join(output_folder, f"{filename}_processed.pkl")
            with open(save_path, "wb") as f:
                pickle.dump({
                    "filename": filename,
                    "cloud_prob": prob.astype(np.float32),   # âœ… ì—°ì† í™•ë¥  ì±„ë„
                    "binary_mask": binary.astype(np.float32), # âœ… ì´ì§„ ë§ˆìŠ¤í¬(0/1)
                    "patches": patches,
                    "positions": positions,
                    "meta": meta
                }, f, protocol=pickle.HIGHEST_PROTOCOL)
            print(f"ğŸ’¾ ì €ì¥: {save_path} | cover={coverage:.2f}%")

            # ì¤‘ë³µ ê²½ë³´: ê°™ì€ bin_md5ê°€ ë„ˆë¬´ ìì£¼ ë‚˜ì˜¤ë©´ í‘œì‹œ
            dup_guard[bin_md5] = dup_guard.get(bin_md5, 0) + 1
            if dup_guard[bin_md5] >= 3:
                print(f"âš ï¸ ë™ì¼ ì´ì§„ ë§ˆìŠ¤í¬ê°€ {dup_guard[bin_md5]}íšŒ ê´€ì¸¡ë¨(bin_md5={bin_md5[:8]}...)")

            # ì‹œê°í™”
            img_path = os.path.join(output_folder, f"{filename}_visual.png")
            proc.visualize_cloud_data(cld, title=f"CLD (raw) - {filename}", save_path=img_path)

            processed_count += 1

        except Exception as e:
            print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            failed_count += 1

    print("\nğŸ‰ ì¼ê´„ ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"âœ… ì„±ê³µ: {processed_count}ê°œ | âŒ ì‹¤íŒ¨: {failed_count}ê°œ")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_folder}")
