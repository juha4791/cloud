# ========================= realtime_prediction_system.py =========================
import os
import json
import time
import csv
import hashlib
import torch
import pickle
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
from collections import deque

# (í•„ìš” ì‹œ í™œì„±í™”) GK2A ì›ë³¸ ë‹¤ìš´ë¡œë“œ/ì „ì²˜ë¦¬ë¥¼ ì“°ë ¤ë©´ ì‚¬ìš©í•˜ì„¸ìš”.
# from gk2a_preprocessor import GK2ACloudProcessor

# cloud_convlstm_model.pyì— ì•„ë˜ ë³„ì¹­ ì¤‘ í•˜ë‚˜ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
# - CloudMovementPredictor = ImprovedCloudMovementPredictor   (ê¶Œì¥ ë³„ì¹­)
# - ë˜ëŠ” ImprovedCloudMovementPredictor ìì²´ë¥¼ importí•´ì„œ asë¡œ ë³„ì¹­
from cloud_convlstm_model import ImprovedCloudMovementPredictor


# ----------------------------- ì„¤ì • -----------------------------
SEQ_LEN = 20          # ì…ë ¥ í”„ë ˆì„ ìˆ˜ (10ë¶„ ê°„ê²© ê°€ì •)
PRED_STEPS = 1        # ì˜ˆì¸¡ ìŠ¤í… ìˆ˜ (t+10m í•œ ìŠ¤í…)
TARGET_HW = (256, 256)
THRESH = 0.5


# ----------------------------- ìœ í‹¸ í•¨ìˆ˜ë“¤ -----------------------------
def _ensure_hw256(mask: np.ndarray, target_size=TARGET_HW) -> np.ndarray:
    """(H,W) ì‹¤ìˆ˜ ë°°ì—´ì„ target_sizeë¡œ ì¤‘ì•™ í¬ë¡­/íŒ¨ë“œ."""
    mask = mask.astype(np.float32)
    H, W = target_size
    h, w = mask.shape
    if h >= H and w >= W:
        sh = (h - H) // 2
        sw = (w - W) // 2
        return mask[sh:sh+H, sw:sw+W]
    # pad
    ph = max(0, (H - h) // 2)
    pw = max(0, (W - w) // 2)
    phe = H - h - ph
    pwe = W - w - pw
    return np.pad(mask, ((ph, phe), (pw, pwe)), mode="constant")


def _load_mask_from_processed_pkl(pkl_path: str) -> np.ndarray:
    """
    gk2a_preprocessor.pyê°€ ë§Œë“  *_processed.pklì—ì„œ ë§ˆìŠ¤í¬ ë¡œë“œ.
    - í™•ë¥  ì±„ë„ì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©: ['prob_mask','cloud_prob','probability','prob']
    - ì—†ìœ¼ë©´ binary_mask ì‚¬ìš©
    - ê°’ ë²”ìœ„ ì •ê·œí™”(0~1), ê²°ì¸¡(-1)â†’0
    """
    with open(pkl_path, "rb") as f:
        data = pickle.load(f)
    m = None
    for key in ["prob_mask", "cloud_prob", "probability", "prob"]:
        if key in data:
            m = np.asarray(data[key]).astype(np.float32)
            break
    if m is None:
        m = np.asarray(data["binary_mask"]).astype(np.float32)
    m = np.where(m == -1, 0, m)
    if m.max() > 1:
        m = m / m.max()
    return _ensure_hw256(m, TARGET_HW)


def _cloud_coverage(mask_or_prob: np.ndarray, thresh: float = THRESH) -> float:
    """
    ì´ì§„ ë§ˆìŠ¤í¬ ë˜ëŠ” í™•ë¥ ë§µì—ì„œ êµ¬ë¦„ ì»¤ë²„ìœ¨(%) ë°˜í™˜.
    - ì…ë ¥ì´ í™•ë¥ ë§µì´ë©´ thresh ê¸°ì¤€ ì´ì§„í™”.
    """
    arr = mask_or_prob
    if arr.dtype != np.bool_ and arr.max() <= 1.0 and arr.min() >= 0.0:
        arr = (arr > thresh).astype(np.float32)
    return float(arr.mean() * 100.0)


def _timestamp_from_filename(fname: str) -> datetime | None:
    """
    íŒŒì¼ëª…ì—ì„œ YYYYMMDDHHMM ì¶”ì¶œ.
    ì˜ˆ: gk2a_ami_le2_cld_ko020lc_202508252150_processed.pkl
    """
    try:
        parts = os.path.basename(fname).split("_")
        for i, p in enumerate(parts):
            if len(p) == 12 and p.isdigit():
                return datetime.strptime(p, "%Y%m%d%H%M")
            if len(p) == 8 and p.isdigit() and i + 1 < len(parts):
                q = parts[i + 1]
                if len(q) == 4 and q.isdigit():
                    return datetime.strptime(p + q, "%Y%m%d%H%M")
    except Exception:
        pass
    return None


def _save_vis(input_seq: np.ndarray, pred_prob: np.ndarray, save_path: str, use_gray_r: bool = False):
    """
    ì‹œê°í™” ì €ì¥:
    - ì…ë ¥ì€ SEQ_LEN ì¤‘ 'ìµœê·¼ 4ì¥'(t-30, -20, -10, -0)ì„ í‘ë°±ìœ¼ë¡œ ë³´ì—¬ì¤Œ
    - ì˜ˆì¸¡ì€ ì»¬ëŸ¬ë°” í¬í•¨
    input_seq: (S, H, W), pred_prob: (H, W)
    """
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    S = input_seq.shape[0]
    pick_ids = [max(0, S-4), max(0, S-3), max(0, S-2), max(0, S-1)]
    titles = ["t-30m", "t-20m", "t-10m", "t-0m"] if S >= 4 else [f"t-{(len(pick_ids)-i)*10}m" for i in range(len(pick_ids))]

    plt.figure(figsize=(3 * (len(pick_ids) + 1), 3))
    for i, idx in enumerate(pick_ids):
        plt.subplot(1, len(pick_ids) + 1, i + 1)
        plt.title(titles[i])
        cmap = "gray_r" if use_gray_r else "gray"
        plt.imshow(input_seq[idx], vmin=0, vmax=1, cmap=cmap)
        plt.axis("off")
    plt.subplot(1, len(pick_ids) + 1, len(pick_ids) + 1)
    plt.title("t+10m (prob)")
    im = plt.imshow(pred_prob, vmin=0, vmax=1)
    plt.colorbar(im, fraction=0.046, pad=0.04)
    plt.axis("off")
    plt.tight_layout()
    plt.savefig(save_path, dpi=200)
    plt.close()


def _save_error_map(gt: np.ndarray, pred_prob: np.ndarray, save_path: str):
    """ê´€ì¸¡(GT) vs ì˜ˆì¸¡(â‰¥0.5) ì˜¤ì°¨ë§µ ì €ì¥."""
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    pred_bin = (pred_prob >= THRESH).astype(np.float32)
    err = np.abs(gt - pred_bin)
    plt.figure(figsize=(4, 4))
    plt.title("Error map (GT vs Predâ‰¥0.5)")
    plt.imshow(err, cmap="hot", vmin=0, vmax=1)
    plt.colorbar()
    plt.axis("off")
    plt.tight_layout()
    plt.savefig(save_path, dpi=150)
    plt.close()


def _hash_mask(mask: np.ndarray) -> str:
    return hashlib.md5(mask.tobytes()).hexdigest()


# ----------------------- ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ í´ë˜ìŠ¤ -----------------------
class RealtimeCloudPredictor:
    """
    ì‹¤ì‹œê°„ êµ¬ë¦„ ì´ë™ ì˜ˆì¸¡ ì‹œìŠ¤í…œ.
    - ìµœê·¼ SEQ_LEN í”„ë ˆì„(10ë¶„ ê°„ê²© ê°€ì •)ì„ ë²„í¼ì— ìŒ“ì•„ t+10m 1ìŠ¤í… ì˜ˆì¸¡.
    - ì…ë ¥ì€ GK2A ì „ì²˜ë¦¬ ê²°ê³¼(*_processed.pkl) ë˜ëŠ” (H,W) numpy ë°°ì—´.
    """

    def __init__(self,
                 model_path: str = "./models/best_cloud_model.pth",
                 data_folder: str = "./realtime_data",
                 device: torch.device | None = None):
        self.model_path = model_path
        self.data_folder = data_folder
        os.makedirs(self.data_folder, exist_ok=True)

        # CSV ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
        self.log_csv = os.path.join(self.data_folder, "prediction_log.csv")
        if not os.path.exists(self.log_csv):
            with open(self.log_csv, "w", newline="", encoding="utf-8") as f:
                writer = csv.writer(f)
                writer.writerow([
                    "run_timestamp", "pred_time", "gt_stamp",
                    "IoU", "Acc", "Brier", "Coverage%",
                    "vis_path", "error_path", "seq_len"
                ])

        # ë””ë°”ì´ìŠ¤
        self.device = device or (torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu"))

        # ëª¨ë¸ ë¡œë“œ
        self.model = self._load_model()

        # ìµœê·¼ ì‹œí€€ìŠ¤ ë²„í¼(í”„ë ˆì„/íƒ€ì„ìŠ¤íƒ¬í”„/í•´ì‹œ)
        self.data_buffer = deque(maxlen=SEQ_LEN)   # (H,W)
        self.ts_buffer = deque(maxlen=SEQ_LEN)     # datetime
        self.hash_buffer = deque(maxlen=SEQ_LEN)   # md5

        # ì˜ˆì¸¡ ê¸°ë¡
        self.predictions = []
        print(f"âœ… ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (device={self.device}, model={os.path.basename(self.model_path)})")

    def _load_model(self) -> torch.nn.Module:
        model = ImprovedCloudMovementPredictor(
            input_size=TARGET_HW,
            sequence_length=SEQ_LEN,
            prediction_steps=PRED_STEPS
        )
        loaded = False
        if os.path.exists(self.model_path):
            state = torch.load(self.model_path, map_location="cpu")

            cand = None
            if isinstance(state, dict):
                if "state_dict" in state and isinstance(state["state_dict"], dict):
                    cand = state["state_dict"]
                elif "model_state_dict" in state and isinstance(state["model_state_dict"], dict):
                    cand = state["model_state_dict"]
                elif all(isinstance(k, str) for k in state.keys()):
                    cand = state  # ìˆœìˆ˜ state_dictë¡œ ì¶”ì •

            if cand is not None:
                incompatible = model.load_state_dict(cand, strict=False)
                loaded = True
                miss = len(getattr(incompatible, "missing_keys", []))
                unexp = len(getattr(incompatible, "unexpected_keys", []))
                total_norm = 0.0
                with torch.no_grad():
                    for p in model.parameters():
                        total_norm += float((p.detach().float() ** 2).sum().cpu())
                print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {self.model_path} | missing={miss}, unexpected={unexp}, param_norm={total_norm:.2e}")
            else:
                print("âš ï¸ ì²´í¬í¬ì¸íŠ¸ í˜•ì‹ì—ì„œ state_dictë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            print(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.model_path} (ë¬´ê²Œì¹˜ ì—†ìŒ ìƒíƒœ)")

        if not loaded:
            print("âš ï¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨ â†’ ëœë¤ ì´ˆê¸°í™” ìƒíƒœì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        model = model.to(self.device).eval()
        return model

    # -------------------- ì…ë ¥(í”„ë ˆì„) ì¶”ê°€ API --------------------
    def add_frame_from_pkl(self, processed_pkl_path: str, timestamp: datetime | None = None, skip_duplicates: bool = True) -> bool:
        """
        *_processed.pkl í•œ ê°œë¥¼ ì½ì–´ ë²„í¼ì— ì¶”ê°€.
        íŒŒì¼ëª…ì—ì„œ ì‹œê°„(YYYYMMDD_HHMM) íŒ¨í„´ì„ ìë™ ì¶”ì¶œí•´ì„œ timestampë¡œ ì‚¬ìš©.
        ì¤‘ë³µ(ì§ì „ í”„ë ˆì„ê³¼ ì™„ì „ ë™ì¼)ì´ë©´ ìŠ¤í‚µ ê°€ëŠ¥.
        """
        mask = _load_mask_from_processed_pkl(processed_pkl_path)  # (H,W)
        h = _hash_mask(mask)
        if skip_duplicates and len(self.hash_buffer) > 0 and self.hash_buffer[-1] == h:
            print(f"âš ï¸ ì¤‘ë³µ í”„ë ˆì„ ê°ì§€ â†’ ìŠ¤í‚µ: {os.path.basename(processed_pkl_path)}")
            return False

        ts = _timestamp_from_filename(processed_pkl_path) or timestamp or datetime.now()
        self.data_buffer.append(mask)
        self.ts_buffer.append(ts)
        self.hash_buffer.append(h)
        fname = os.path.basename(processed_pkl_path)
        print(f"â• í”„ë ˆì„ ì¶”ê°€: {fname} at {ts.isoformat()} "
              f"(buffer {len(self.data_buffer)}/{SEQ_LEN}, cover={_cloud_coverage(mask):.1f}%)")
        return True

    def add_frame_from_array(self, mask_2d: np.ndarray, timestamp: datetime | None = None, skip_duplicates: bool = True) -> bool:
        """
        (H,W) numpy ë°°ì—´(0~1)ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ë²„í¼ì— ì¶”ê°€.
        """
        mask = mask_2d.astype(np.float32)
        mask = np.where(mask == -1, 0, mask)
        if mask.max() > 1:
            mask = mask / mask.max()
        mask = _ensure_hw256(mask, TARGET_HW)
        h = _hash_mask(mask)
        if skip_duplicates and len(self.hash_buffer) > 0 and self.hash_buffer[-1] == h:
            print("âš ï¸ ì¤‘ë³µ í”„ë ˆì„(ë°°ì—´) ê°ì§€ â†’ ìŠ¤í‚µ")
            return False

        ts = timestamp or datetime.now()
        self.data_buffer.append(mask)
        self.ts_buffer.append(ts)
        self.hash_buffer.append(h)
        print(f"â• í”„ë ˆì„ ì¶”ê°€(ë°°ì—´): {ts.isoformat()} (buffer {len(self.data_buffer)}/{SEQ_LEN}, cover={_cloud_coverage(mask):.1f}%)")
        return True

    # -------------------------- ì˜ˆì¸¡ API --------------------------
    def make_prediction(self, save_dir: str = "./demo_outputs", use_gray_r: bool = False) -> dict | None:
        """
        ìµœê·¼ SEQ_LEN í”„ë ˆì„ìœ¼ë¡œ t+10m 1ìŠ¤í… ì˜ˆì¸¡.
        - return: {'timestamp', 'prediction_time', 'prediction'(np.ndarray), 'vis_path', 'coverage%'}
        """
        if len(self.data_buffer) < SEQ_LEN:
            print(f"âš ï¸ ì˜ˆì¸¡ í”„ë ˆì„ ë¶€ì¡± (í•„ìš”={SEQ_LEN}, í˜„ì¬={len(self.data_buffer)})")
            return None

        try:
            seq = np.stack(list(self.data_buffer), axis=0)   # (S, H, W)
            seq_t = torch.from_numpy(seq).float().unsqueeze(0).unsqueeze(2).to(self.device)  # (1,S,1,H,W)

            with torch.no_grad():
                out = self.model(seq_t)                      # (1,1,H,W) ë˜ëŠ” (1,PRED_STEPS,1,H,W) êµ¬ì¡°ì¼ ìˆ˜ë„ ìˆìŒ
                if out.ndim == 5:  # (1,steps,1,H,W) â†’ í•œ ìŠ¤í…ë§Œ ì‚¬ìš©
                    out = out[:, 0]
                out_min = float(out.min().detach().cpu()); out_max = float(out.max().detach().cpu())
                if 0.0 <= out_min and out_max <= 1.0:
                    prob = out.cpu().numpy()[0, 0]
                    print(f"[Predict] raw_out in [0,1] â†’ sigmoid ìƒëµ | range=[{out_min:.4f}, {out_max:.4f}]")
                else:
                    prob = torch.sigmoid(out).cpu().numpy()[0, 0]
                    print(f"[Predict] raw_out logits â†’ sigmoid ì ìš© | range=[{out_min:.4f}, {out_max:.4f}]")

            # ì‹œê°í™” ì €ì¥(ìµœê·¼ 4ì¥ë§Œ ë³´ì—¬ì¤Œ)
            os.makedirs(save_dir, exist_ok=True)
            vis_path = os.path.join(save_dir, f"prediction_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png")
            _save_vis(seq, prob, vis_path, use_gray_r=use_gray_r)

            pred_time = (self.ts_buffer[-1] if len(self.ts_buffer) else datetime.now()) + timedelta(minutes=10)
            result = {
                "timestamp": datetime.now().isoformat(),
                "prediction_time": pred_time.isoformat(),
                "prediction": prob,               # (H,W) í™•ë¥ ë§µ
                "vis_path": vis_path,
                "coverage%": _cloud_coverage(prob, thresh=THRESH)
            }
            self.predictions.append(result)
            print(f"ğŸ”® ì˜ˆì¸¡ ì™„ë£Œ: t+10m={pred_time.strftime('%Y-%m-%d %H:%M:%S')} | "
                  f"coverageâ‰ˆ{result['coverage%']:.1f}% | saved â†’ {vis_path}")

            # ë¼ë²¨ ê·¹ì„±(ë¬´ì—‡ì´ 1ì¸ì§€) ë¹ ë¥¸ ì ê²€
            last_obs = self.data_buffer[-1]
            mean_on_ones = float(result["prediction"][last_obs == 1].mean()) if (last_obs == 1).any() else float('nan')
            mean_on_zeros = float(result["prediction"][last_obs == 0].mean()) if (last_obs == 0).any() else float('nan')
            print(f"[Polarity] mean(pred | obs=1)={mean_on_ones:.4f}, mean(pred | obs=0)={mean_on_zeros:.4f}")

            return result

        except Exception as e:
            print(f"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return None

    # ---------------------- í‰ê°€/ëŒ€ì‹œë³´ë“œ ----------------------
    def evaluate_with_next_observation(self,
                                       data_folder: str,
                                       prefix: str,
                                       suffix: str,
                                       result: dict,
                                       save_dir: str = "./demo_outputs",
                                       invert_gt: bool = False) -> dict | None:
        """
        ë§ˆì§€ë§‰ ì…ë ¥ ì‹œê° +10ë¶„ì˜ *_processed.pklì„ ì°¾ì•„ ì •ëŸ‰ í‰ê°€.
        invert_gt=True ì´ë©´ GTë¥¼ 1-gtë¡œ ë’¤ì§‘ì–´ í‰ê°€(ë¼ë²¨ ê·¹ì„± ë³´ì •).
        ë˜í•œ CSV ë¡œê·¸ì™€ ì—ëŸ¬ë§µì„ ì €ì¥í•©ë‹ˆë‹¤.
        """
        if len(self.ts_buffer) == 0 or result is None:
            return None

        gt_ts = self.ts_buffer[-1] + timedelta(minutes=10)
        gt_stamp = gt_ts.strftime("%Y%m%d%H%M")
        gt_name = f"{prefix}{gt_stamp}{suffix}"
        gt_path = os.path.join(data_folder, gt_name)
        if not os.path.exists(gt_path):
            print(f"â„¹ï¸ GT ì—†ìŒ: {gt_path}")
            return None

        gt = _load_mask_from_processed_pkl(gt_path).astype(np.float32)
        if invert_gt:
            gt = 1.0 - gt

        pred = result["prediction"].astype(np.float32)
        pred_bin = (pred >= THRESH).astype(np.float32)

        # IoU, Acc, Brier
        intersection = np.logical_and(pred_bin == 1, gt == 1).sum()
        union = np.logical_or(pred_bin == 1, gt == 1).sum()
        iou = float(intersection / max(1, union))
        acc = float((pred_bin == gt).mean())
        brier = float(((pred - gt) ** 2).mean())

        # ì—ëŸ¬ë§µ ì €ì¥
        err_path = os.path.join(save_dir, f"error_{gt_stamp}.png")
        _save_error_map(gt, pred, err_path)

        # CSV ë¡œê·¸ ì €ì¥
        with open(self.log_csv, "a", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow([
                result["timestamp"],
                result["prediction_time"],
                gt_stamp,
                f"{iou:.6f}",
                f"{acc:.6f}",
                f"{brier:.6f}",
                f"{result['coverage%']:.2f}",
                result["vis_path"],
                err_path,
                SEQ_LEN
            ])

        print(f"[Eval @ {gt_stamp}] IoU={iou:.3f}, Acc={acc:.3f}, Brier={brier:.4f} | error_map â†’ {err_path} | invert_gt={invert_gt}")

        return {"IoU": iou, "Acc": acc, "Brier": brier, "gt_path": gt_path, "error_path": err_path}

    def create_prediction_dashboard(self,
                                    last_obs: np.ndarray | None,
                                    last_pred: np.ndarray | None,
                                    save_path: str = "prediction_dashboard.html",
                                    metrics: dict | None = None):
        """
        ê°„ë‹¨ HTML ëŒ€ì‹œë³´ë“œ ìƒì„±.
        - last_obs: ìµœê·¼ ê´€ì¸¡(0~1 ì´ì§„/í™•ë¥ ), (H,W) or None
        - last_pred: ìµœê·¼ ì˜ˆì¸¡ í™•ë¥ , (H,W) or None
        - metrics: {'IoU','Acc','Brier'} ë“± í‰ê°€ ê²°ê³¼(ìˆìœ¼ë©´ í‘œê¸°)
        """
        obs_cov = _cloud_coverage(last_obs) if last_obs is not None else None
        pred_cov = _cloud_coverage(last_pred) if last_pred is not None else None
        now_kst = datetime.now().strftime("%Y-%m-%d %H:%M KST")
        pred_kst = (datetime.now() + timedelta(minutes=10)).strftime("%Y-%m-%d %H:%M KST")

        metrics_html = ""
        if metrics is not None:
            iou = metrics.get("IoU", float("nan"))
            acc = metrics.get("Acc", float("nan"))
            brier = metrics.get("Brier", float("nan"))
            metrics_html = f"""
            <h3>ğŸ“Š ìµœê·¼ í‰ê°€ ì§€í‘œ</h3>
            <ul>
                <li>IoU: {iou:.3f}</li>
                <li>Acc: {acc:.3f}</li>
                <li>Brier: {brier:.4f}</li>
            </ul>
            """

        html = f"""<!DOCTYPE html>
<html>
<head>
    <title>êµ¬ë¦„ ì´ë™ ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ</title>
    <meta charset="UTF-8">
    <meta http-equiv="refresh" content="600">
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; }}
        .header {{ text-align: center; color: #2c3e50; }}
        .prediction-grid {{ display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-top: 20px; }}
        .prediction-box {{ border: 1px solid #ddd; padding: 15px; border-radius: 8px; }}
        .timestamp {{ color: #7f8c8d; font-size: 14px; }}
        .status {{ padding: 5px 10px; border-radius: 4px; color: white; background-color: #27ae60; display: inline-block; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸŒ¤ï¸ í•œêµ­ êµ¬ë¦„ ì´ë™ ì˜ˆì¸¡ ì‹œìŠ¤í…œ</h1>
        <p>GK2A ìœ„ì„± ë°ì´í„° ê¸°ë°˜ ì‹¤ì‹œê°„ êµ¬ë¦„ ì˜ˆì¸¡</p>
        <div class="status">ìš´ì˜ ì¤‘</div>
    </div>

    <div class="prediction-grid">
        <div class="prediction-box">
            <h3>ğŸ“¡ ìµœê·¼ ê´€ì¸¡</h3>
            <p class="timestamp">ì—…ë°ì´íŠ¸: {now_kst}</p>
            <p>êµ¬ë¦„ ì»¤ë²„: {obs_cov:.1f}%</p>
        </div>

        <div class="prediction-box">
            <h3>ğŸ”® 10ë¶„ í›„ ì˜ˆì¸¡</h3>
            <p class="timestamp">ì˜ˆì¸¡ ì‹œê°„: {pred_kst}</p>
            <p>ì˜ˆìƒ êµ¬ë¦„ ì»¤ë²„: {pred_cov:.1f}%</p>
        </div>
    </div>

    {metrics_html}
</body>
</html>"""
        with open(save_path, "w", encoding="utf-8") as f:
            f.write(html)
        print(f"âœ… ëŒ€ì‹œë³´ë“œ ì €ì¥: {save_path}")


# --------------------------------- ë°ëª¨ ì‹¤í–‰ ---------------------------------
if __name__ == "__main__":
    """
    ê°„ë‹¨ ì‹œí˜„:
    1) ì „ì²˜ë¦¬ëœ GK2A íŒŒì¼ 20ê°œë¥¼ ì‹œê°„ ìˆœì„œëŒ€ë¡œ ë²„í¼ì— ì¶”ê°€(ì¤‘ë³µ íšŒí”¼)
    2) t+10m ì˜ˆì¸¡ì„ ìˆ˜í–‰
    3) ì •ë‹µ(+10ë¶„)ìœ¼ë¡œ í‰ê°€ ë° ë¡œê·¸/ì˜¤ì°¨ë§µ ì €ì¥
    4) ëŒ€ì‹œë³´ë“œ ìƒì„±
    """
    # 1) ëª¨ë¸ ê²½ë¡œ ìë™ ì„ íƒ: improved íŒŒì¼ì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
    default_model = "./models/best_cloud_model.pth"
    improved_model = "./best_cloud_model_improved.pth"  # ì—…ë¡œë“œ/ì‹¤í—˜ íŒŒì¼ ëŒ€ì‘
    model_path = improved_model if os.path.exists(improved_model) else default_model

    predictor = RealtimeCloudPredictor(model_path=model_path, data_folder="./realtime_data")

    # 2) ì „ì²˜ë¦¬ëœ pkl í›„ë³´(ëª…ì‹œì  ëª©ë¡ì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©)
    explicit_targets = [
        # í•„ìš” ì‹œ ì—¬ê¸°ì— 20ê°œ ê²½ë¡œë¥¼ ì§ì ‘ ë„£ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # ì˜ˆì‹œ(4ê°œë§Œ ì ì–´ë‘ ): ì´í›„ ìë™ ë³´ì¶© ë¡œì§ì´ ë‚˜ë¨¸ì§€ë¥¼ ì±„ì›€
        "./processed_cloud_data/gk2a_ami_le2_cld_ko020lc_202508252150_processed.pkl",
        "./processed_cloud_data/gk2a_ami_le2_cld_ko020lc_202508252200_processed.pkl",
        "./processed_cloud_data/gk2a_ami_le2_cld_ko020lc_202508252210_processed.pkl",
        "./processed_cloud_data/gk2a_ami_le2_cld_ko020lc_202508252220_processed.pkl",
    ]
    existing_targets = [p for p in explicit_targets if os.path.exists(p)]

    added = 0
    # 2-1) ëª…ì‹œ íŒŒì¼ ë¨¼ì € ë„£ê¸°(ì¤‘ë³µì€ ë‚´ë¶€ì—ì„œ ìŠ¤í‚µë  ìˆ˜ ìˆìŒ)
    for p in existing_targets:
        ok = predictor.add_frame_from_pkl(p, skip_duplicates=True)
        if ok:
            added += 1
        if added >= SEQ_LEN:
            break

    # 2-2) ë¶€ì¡±í•˜ë©´ í´ë”ì—ì„œ ë³´ì¶©(ìµœì‹  â†’ ê³¼ê±° ìˆœì„œë¡œ ë‚´ë ¤ê°€ë©° uniqueí•˜ê²Œ ì±„ì›€)
    if added < SEQ_LEN:
        print("â„¹ï¸ ëŒ€ì²´ í”„ë ˆì„ì„ íƒìƒ‰í•©ë‹ˆë‹¤.")
        folder = "./processed_cloud_data"
        prefix = "gk2a_ami_le2_cld_ko020lc_"
        suffix = "_processed.pkl"

        candidates = []
        try:
            for fn in os.listdir(folder):
                if fn.startswith(prefix) and fn.endswith(suffix):
                    mid = fn[len(prefix):-len(suffix)]
                    if len(mid) == 12 and mid.isdigit():
                        try:
                            ts = datetime.strptime(mid, "%Y%m%d%H%M")
                            candidates.append((ts, os.path.join(folder, fn)))
                        except Exception:
                            pass
        except FileNotFoundError:
            print(f"âš ï¸ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {folder}")

        # ìµœì‹  â†’ ê³¼ê±°
        candidates.sort(key=lambda x: x[0], reverse=True)
        # ì´ë¯¸ ë„£ì€ ê²½ë¡œ ì œì™¸
        used = set(os.path.abspath(p) for p in existing_targets)
        for ts, p in candidates:
            if os.path.abspath(p) in used:
                continue
            ok = predictor.add_frame_from_pkl(p, skip_duplicates=True)
            if ok:
                added += 1
                used.add(os.path.abspath(p))
            if added >= SEQ_LEN:
                break

    # 2-3) ê·¸ë˜ë„ ë¶€ì¡±í•˜ë©´ ëœë¤ìœ¼ë¡œ ì±„ì›€(ë°ëª¨ìš©)
    if added < SEQ_LEN:
        print(f"âš ï¸ ìœ íš¨í•œ ì „ì²˜ë¦¬ íŒŒì¼ì´ {SEQ_LEN}ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤. ë°ëª¨ìš© ëœë¤ í”„ë ˆì„ìœ¼ë¡œ ì±„ì›ë‹ˆë‹¤.")
        rnd = (np.random.rand(*TARGET_HW) > 0.6).astype(np.float32)
        while added < SEQ_LEN:
            predictor.add_frame_from_array(rnd, skip_duplicates=False)
            added += 1

    if added < SEQ_LEN:
        print("ğŸš« ì‹¤ì‹œê°„ êµ¬ë¦„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì‹œì—° ì¢…ë£Œ(í”„ë ˆì„ ë¶€ì¡±)")
    else:
        # (ì„ íƒ) ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸: ëª¨ë¸ ì¶œë ¥ ë²”ìœ„ í™•ì¸
        x = torch.randn(1, SEQ_LEN, 1, *TARGET_HW, device=predictor.device)
        with torch.no_grad():
            y = predictor.model(x)
            y_min = float(y.min().detach().cpu())
            y_max = float(y.max().detach().cpu())
        print(f"[SMOKE] model raw_out range on random input: [{y_min:.4f}, {y_max:.4f}]")

        # 3) ì˜ˆì¸¡ ì‹¤í–‰
        result = predictor.make_prediction(save_dir="./demo_outputs", use_gray_r=False)

        # 3-1) ì •ë‹µ(+10ë¶„)ìœ¼ë¡œ í‰ê°€ ë° ë¡œê·¸/ì˜¤ì°¨ë§µ ì €ì¥
        metrics = None
        if result is not None:
            metrics = predictor.evaluate_with_next_observation(
                data_folder="./processed_cloud_data",
                prefix="gk2a_ami_le2_cld_ko020lc_",
                suffix="_processed.pkl",
                result=result,
                save_dir="./demo_outputs",
                invert_gt=False  # í•„ìš” ì‹œ Trueë¡œ ê·¹ì„± ë³´ì •
            )

        # 4) ëŒ€ì‹œë³´ë“œ ìƒì„± (í‰ê°€ ê²°ê³¼ í¬í•¨)
        if result is not None:
            last_obs = predictor.data_buffer[-1]           # ë§ˆì§€ë§‰ ê´€ì¸¡(í˜•ì‹ìƒ)
            last_pred = result["prediction"]               # í™•ë¥ ë§µ
            predictor.create_prediction_dashboard(last_obs, last_pred,
                                                  save_path="prediction_dashboard.html",
                                                  metrics=metrics)

        print("ğŸš€ ì‹¤ì‹œê°„ êµ¬ë¦„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì‹œì—° ì™„ë£Œ")
# ==============================================================================
